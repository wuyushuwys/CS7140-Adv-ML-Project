{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import normalize\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from time import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_signal(data):\n",
    "    l = len(data)\n",
    "    splited_data = []\n",
    "    l -= 128*5 # skip first 5 seconds as well as the first clip in the Ext_annotation, Data sampled in 128Hz\n",
    "    while l-20*128>0:\n",
    "        splited_data.append(data[-l:-l+128*20])\n",
    "        l -= 128*20\n",
    "    splited_data.append(data[-128*20:]) # split the last clip according to the docs\n",
    "    return splited_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ext_annotation(data):\n",
    "    ext_annotation = [] # extract labels_ext_annotation without the first clip according to the \n",
    "    for video_ext_annotation in data:\n",
    "        ext_annotation += list(video_ext_annotation[1:, 1:])\n",
    "    return ext_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exist, loading...\n"
     ]
    }
   ],
   "source": [
    "files = glob(\"./data_preprocessed/*/*.mat\")\n",
    "files.sort()\n",
    "\n",
    "if os.path.isfile('GSR_DATA.npy') and os.path.isfile('ground_truth.npy'):\n",
    "    print(\"File already exist, loading...\")\n",
    "    GSR_DATA = np.load('GSR_DATA.npy')\n",
    "    ground_truth = np.load('ground_truth.npy')\n",
    "else:\n",
    "    print(\"Extracting data...\")\n",
    "    GSR_DATA = []\n",
    "    ground_truth = []\n",
    "    \n",
    "    for f in files:\n",
    "        if '08' not in f and '24' not in f and '28' not in f:\n",
    "            part_data = loadmat(f) # load participant's all preprocessed physiological data.\n",
    "            _, video_iter =  part_data['joined_data'].shape\n",
    "            group_flag = '07' in f or '01' in f or '02' in f or '16' in f or\\\n",
    "                '15' in f or '11' in f or '12' in f or '10' in f or\\\n",
    "                '06' in f or '32' in f or '04' in f or '03' in f or\\\n",
    "                '29' in f or '5' in f or '27' in f or '21' in f or\\\n",
    "                '18' in f or '14' in f or '17' in f or '22' in f          \n",
    "            if group_flag:\n",
    "                video_iter -=4\n",
    "                part_ext_annotation = part_data['labels_ext_annotation'][0,:-4]# load participant's labels ext_annotation\n",
    "            else:\n",
    "                part_ext_annotation = part_data['labels_ext_annotation'][0,:]# load participant's labels ext_annotation\n",
    "            ground_truth += extract_ext_annotation(part_ext_annotation)\n",
    "                \n",
    "            for idx in range(video_iter):\n",
    "                phys_data = part_data['joined_data'][0, idx] # the preprocessed physiological data of #idx video (not videoID)\n",
    "                part_gsr_data = phys_data[:,16]\n",
    "                GSR_DATA += split_signal(part_gsr_data)\n",
    "\n",
    "    GSR_DATA = np.array(GSR_DATA)\n",
    "    ground_truth = np.array(ground_truth)\n",
    "    np.save(\"GSR_DATA\" ,GSR_DATA)\n",
    "    np.save(\"ground_truth\", ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6516, 2560)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSR_DATA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GSRDataset(torch.utils.data.Dataset):\n",
    "    # Create customized dataset\n",
    "    def __init__(self, GSR, ground_truth=None, transforms=None):\n",
    "        self.X = GSR\n",
    "        self.y = ground_truth\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, i): \n",
    "        X = torch.Tensor(self.X[i,:]).unsqueeze(0)\n",
    "        y = torch.Tensor(self.y[i,:])\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gsr_norm = normalize(GSR_DATA, norm='l2')\n",
    "# gsr_norm = GSR_DATA/1000\n",
    "dataset = GSRDataset(GSR_DATA, ground_truth)\n",
    "test_split = 0.3\n",
    "num_data = len(dataset)\n",
    "num_train = int(num_data*test_split)\n",
    "num_test = num_data - num_train\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [num_train, num_test])\n",
    "\n",
    "train_data = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_data = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size=11, stride=5)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=7,stride=3)\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 2)\n",
    "        \n",
    "        \n",
    "        self.pool = nn.MaxPool1d(4)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "#         print(x.shape)\n",
    "        x = x.view(-1, self.flatten_feature(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def flatten_feature(self, x):\n",
    "        num_feature = 1\n",
    "        for d in x.size()[1:]:\n",
    "            num_feature *= d\n",
    "        return num_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, inputs, device, criterion=None):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in inputs:\n",
    "            X, y = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(X)\n",
    "            total_loss += criterion(outputs, y)\n",
    "    return float(total_loss/len(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Epoch [20/1000]\t\ttrain loss: 3.2007\t\ttest loss:2.4524\n",
      "### Epoch [40/1000]\t\ttrain loss: 0.0558\t\ttest loss:100.4619\n",
      "### Epoch [60/1000]\t\ttrain loss: 18.9487\t\ttest loss:0.1324\n",
      "### Epoch [80/1000]\t\ttrain loss: 5.9309\t\ttest loss:0.638\n",
      "### Epoch [100/1000]\t\ttrain loss: 3.3108\t\ttest loss:0.1953\n",
      "### Epoch [120/1000]\t\ttrain loss: 55.117\t\ttest loss:3.4188\n",
      "### Epoch [140/1000]\t\ttrain loss: 114.9206\t\ttest loss:8.1224\n",
      "### Epoch [160/1000]\t\ttrain loss: 58.4407\t\ttest loss:2.6598\n",
      "### Epoch [180/1000]\t\ttrain loss: 0.0621\t\ttest loss:0.0631\n",
      "### Epoch [200/1000]\t\ttrain loss: 0.2006\t\ttest loss:0.0741\n",
      "### Epoch [220/1000]\t\ttrain loss: 48.1982\t\ttest loss:0.1404\n",
      "### Epoch [240/1000]\t\ttrain loss: 1.079\t\ttest loss:0.1733\n",
      "### Epoch [260/1000]\t\ttrain loss: 24.9356\t\ttest loss:1.274\n",
      "### Epoch [280/1000]\t\ttrain loss: 0.1711\t\ttest loss:0.1733\n",
      "### Epoch [300/1000]\t\ttrain loss: 0.2286\t\ttest loss:0.2265\n",
      "### Epoch [320/1000]\t\ttrain loss: 0.267\t\ttest loss:0.2683\n",
      "### Epoch [340/1000]\t\ttrain loss: 0.3046\t\ttest loss:0.306\n",
      "### Epoch [360/1000]\t\ttrain loss: 0.3817\t\ttest loss:0.3833\n",
      "### Epoch [380/1000]\t\ttrain loss: 0.389\t\ttest loss:0.3906\n",
      "### Epoch [400/1000]\t\ttrain loss: 0.3762\t\ttest loss:0.3778\n",
      "### Epoch [420/1000]\t\ttrain loss: 0.4442\t\ttest loss:0.4458\n",
      "### Epoch [440/1000]\t\ttrain loss: 0.4791\t\ttest loss:0.4806\n",
      "### Epoch [460/1000]\t\ttrain loss: 0.4738\t\ttest loss:0.4753\n",
      "### Epoch [480/1000]\t\ttrain loss: 0.4758\t\ttest loss:0.4777\n",
      "### Epoch [500/1000]\t\ttrain loss: 0.4431\t\ttest loss:0.4446\n",
      "### Epoch [520/1000]\t\ttrain loss: 0.4143\t\ttest loss:0.4158\n",
      "### Epoch [540/1000]\t\ttrain loss: 0.3797\t\ttest loss:0.3812\n",
      "### Epoch [560/1000]\t\ttrain loss: 0.3139\t\ttest loss:0.3153\n",
      "### Epoch [580/1000]\t\ttrain loss: 0.2451\t\ttest loss:0.246\n",
      "### Epoch [600/1000]\t\ttrain loss: 0.1928\t\ttest loss:0.1937\n",
      "### Epoch [620/1000]\t\ttrain loss: 0.1388\t\ttest loss:0.1395\n",
      "### Epoch [640/1000]\t\ttrain loss: 0.0918\t\ttest loss:0.0924\n",
      "### Epoch [660/1000]\t\ttrain loss: 0.0511\t\ttest loss:0.0515\n",
      "### Epoch [680/1000]\t\ttrain loss: 0.0274\t\ttest loss:0.0276\n",
      "### Epoch [700/1000]\t\ttrain loss: 0.0155\t\ttest loss:0.0155\n",
      "### Epoch [720/1000]\t\ttrain loss: 0.0109\t\ttest loss:0.0109\n",
      "Test loss converging\n",
      "Early Stop\n",
      "### Epoch [725/1000]\t\ttrain loss: 0.0099\t\ttest loss:0.0098\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('./runs/GSRmodel_CNN_3layers')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Model()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.1)\n",
    "model.to(device)\n",
    "total_epoch = 1000\n",
    "inputs = next(iter(train_data))[0].to(device)\n",
    "writer.add_graph(model, inputs)\n",
    "old_test_loss = 0\n",
    "for epoch in range(1, total_epoch+1):\n",
    "    start = time()\n",
    "    for i, data in enumerate(train_data):\n",
    "        \n",
    "        model.train()\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = data[0].to(device)\n",
    "        labels = data[1].to(device)\n",
    "        # zero the parameter gradients\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss = test(model, train_data, device, criterion)\n",
    "    test_loss = test(model, test_data, device, criterion)\n",
    "    writer.add_scalar('Test/Loss', test_loss, epoch)\n",
    "    writer.add_scalar('Train/Loss', train_loss, epoch)\n",
    "    if abs(old_test_loss-test_loss) < 10e-3:\n",
    "        print(\"Test loss converging\\nEarly Stop\")\n",
    "        print(\"### Epoch [{}/{}]\\t\\ttrain loss: {}\\t\\ttest loss:{}\"\n",
    "              .format(epoch,total_epoch, round(train_loss, 4), round(test_loss, 4)))\n",
    "        break\n",
    "    if epoch % 20 == 0:\n",
    "        print(\"### Epoch [{}/{}]\\t\\ttrain loss: {}\\t\\ttest loss:{}\"\n",
    "              .format(epoch,total_epoch, round(train_loss, 4), round(test_loss, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
